import json
import re
import traceback
from datetime import datetime, timezone
from typing import Any, Dict, List, Union

from pydantic import ValidationError

from src.app.tools.data_processing_tools import process_raw_data_for_criteria
from src.app.agents.web_search_agent.run import process_todays_data, run_web_search_agent
from src.app.agents.web_search_agent.tools import (
    get_bank_and_products,
    save_raw_data,
)
from src.app.domain.models import WebSearchItem, WebSearchResult
from src.app.tools.data_processor import DataProcessor  # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –æ–±—Ä–∞–±–æ—Ç—á–∏–∫ –¥–∞–Ω–Ω—ã—Ö


def normalize_agent_response(raw_response: Any) -> List[Dict[str, str]]:
    """
    –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç –æ—Ç–≤–µ—Ç –∞–≥–µ–Ω—Ç–∞ –≤ —Å–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π —Å –ø–æ–ª—è–º–∏ source –∏ content

    –û–∂–∏–¥–∞–µ—Ç—Å—è, —á—Ç–æ –∞–≥–µ–Ω—Ç –≤–µ—Ä–Ω–µ—Ç JSON –≤ —Ñ–æ—Ä–º–∞—Ç–µ:
    [{"source": "url", "content": "—Ç–µ–∫—Å—Ç"}, ...]

    Args:
        raw_response: –°—ã—Ä–æ–π –æ—Ç–≤–µ—Ç –æ—Ç –∞–≥–µ–Ω—Ç–∞

    Returns:
        List[Dict[str, str]]: –°–ø–∏—Å–æ–∫ –æ–±—ä–µ–∫—Ç–æ–≤ –≤ —Ñ–æ—Ä–º–∞—Ç–µ {'source': url, 'content': text}
    """
    if not raw_response:
        print("No raw response received")
        return []

    # –ï—Å–ª–∏ –æ—Ç–≤–µ—Ç —É–∂–µ —Å–ø–∏—Å–æ–∫ —Å –Ω—É–∂–Ω–æ–π —Å—Ç—Ä—É–∫—Ç—É—Ä–æ–π
    if isinstance(raw_response, list) and all(
        isinstance(item, dict) and "source" in item and "content" in item
        for item in raw_response
    ):
        print(f"Response already in correct format with {len(raw_response)} items")
        return raw_response

    # –ü—ã—Ç–∞–µ–º—Å—è —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å –∫–∞–∫ JSON —Å—Ç—Ä–æ–∫—É
    try:
        if isinstance(raw_response, str):
            # –£–±–∏—Ä–∞–µ–º markdown —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∏ –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã
            clean_text = re.sub(r"```json|```", "", raw_response).strip()
            if clean_text.startswith("[") and clean_text.endswith("]"):
                try:
                    parsed = json.loads(clean_text)
                    if isinstance(parsed, list) and all(
                        isinstance(item, dict)
                        and "source" in item
                        and "content" in item
                        for item in parsed
                    ):
                        print(f"Parsed JSON with {len(parsed)} items")
                        return parsed
                except json.JSONDecodeError as e:
                    print(f"JSON parsing failed: {str(e)}")
                    print(f"Problematic JSON: {clean_text}")
    except Exception as e:
        print(f"Error during JSON parsing attempt: {str(e)}")

    print("Failed to parse response as valid JSON with source/content structure")
    return []


def process_search_results(
    query: Dict[str, Dict[str, int]], raw_response: Any
) -> Union[WebSearchResult, None]:
    """
    –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–∏—Å–∫–∞ –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –≤–∞–ª–∏–¥–∏—Ä–æ–≤–∞–Ω–Ω—É—é –º–æ–¥–µ–ª—å

    Args:
        query: –°–ª–æ–≤–∞—Ä—å —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ –∑–∞–ø—Ä–æ—Å–µ
        raw_response: –°—ã—Ä–æ–π –æ—Ç–≤–µ—Ç –æ—Ç –∞–≥–µ–Ω—Ç–∞

    Returns:
        WebSearchResult: –í–∞–ª–∏–¥–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –º–æ–¥–µ–ª—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∏–ª–∏ None –µ—Å–ª–∏ –Ω–µ—Ç –≤–∞–ª–∏–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
    """
    prompt = list(query.keys())[0]
    metadata = list(query.values())[0]

    bank_id = metadata["bank_id"]
    product_id = metadata["product_id"]

    print(f"Processing results for bank_id={bank_id}, product_id={product_id}")

    # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –æ—Ç–≤–µ—Ç –≤ –Ω—É–∂–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç
    normalized_items = normalize_agent_response(raw_response)

    if not normalized_items:
        print(
            f"No valid items found after normalization for bank_id={bank_id}, product_id={product_id}"
        )
        return None

    print(f"Found {len(normalized_items)} items after normalization")

    # –°–æ–∑–¥–∞–µ–º —Å–ø–∏—Å–æ–∫ WebSearchItem
    items = []
    for i, item in enumerate(normalized_items):
        source = item.get("source", "").strip()
        content = item.get("content", "").strip()

        if not source or not content:
            print(f"Skipping item {i + 1}: missing source or content")
            continue

        try:
            items.append(WebSearchItem(source=source, content=content))
            print(
                f"Added valid item {i + 1}: source='{source}', content length={len(content)}"
            )
        except ValidationError as ve:
            print(f"Item validation failed for item {i + 1}: {ve}")
            continue

    if not items:
        print(
            f"No valid items after validation for bank_id={bank_id}, product_id={product_id}"
        )
        return None

    print(
        f"Successfully validated {len(items)} items for bank_id={bank_id}, product_id={product_id}"
    )
    return WebSearchResult(bank_id=bank_id, product_id=product_id, items=items)


def get_raw_data():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Å—ã—Ä—ã—Ö –¥–∞–Ω–Ω—ã—Ö"""
    queries = get_bank_and_products()

    if not queries:
        print("No queries to process")
        return

    print(f"Processing {len(queries)} search queries...")
    any_data_saved = False

    for query in queries:
        try:
            prompt = list(query.keys())[0]
            metadata = list(query.values())[0]

            bank_id = metadata["bank_id"]
            # –•–∞—Ä–¥–∫–æ–¥, —Ç–∞–∫ –∫–∞–∫ –ø–æ–∏—Å–∫ –∏–Ω–æ–≥–¥–∞ –ø—Ä–µ—Ä—ã–≤–∞–ª—Å—è
            # if bank_id < 6:
            #     continue
            product_id = metadata["product_id"]
            # if product_id <= 17 and bank_id == 6:
            #     continue

            print(f"\nProcessing search for bank_id={bank_id}, product_id={product_id}")
            print(f"Search query: {prompt[:100]}...")

            messages = [{"role": "user", "content": prompt}]
            raw_response = run_web_search_agent({"messages": messages})

            print("Raw agent response received")
            print(f"Response type: {type(raw_response)}")
            if isinstance(raw_response, str) and len(raw_response) > 200:
                print(f"Response preview: {raw_response[:200]}...")
            else:
                print(f"Response: {raw_response}")

            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            result = process_search_results(query, raw_response)

            if not result:
                print(
                    f"No valid results for bank_id={bank_id}, product_id={product_id}"
                )
                continue

            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –±–∞–∑—É
            success = save_raw_data(result)

            if success:
                any_data_saved = True
                print(
                    f"Successfully processed {len(result.items)} sources for bank_id={bank_id}, product_id={product_id}"
                )
            else:
                print(
                    f"Failed to save results for bank_id={bank_id}, product_id={product_id}"
                )

        except Exception as e:
            print(
                f"Error processing query for bank_id={bank_id}, product_id={product_id}: {str(e)}"
            )
            traceback.print_exc()
            continue

    # –ü–æ—Å–ª–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –≤—Å–µ—Ö –∑–∞–ø—Ä–æ—Å–æ–≤ –∑–∞–ø—É—Å–∫–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É –¥–∞–Ω–Ω—ã—Ö –∑–∞ —Å–µ–≥–æ–¥–Ω—è
    if any_data_saved:
        print("\n" + "=" * 50)
        print("STARTING DATA PROCESSING FOR TODAY'S RAW DATA")
        print("=" * 50)

        try:
            start_time = datetime.now()
            processor = DataProcessor()
            processing_success = processor.run()

            end_time = datetime.now()
            duration = end_time - start_time

            if processing_success:
                print(
                    f"\nDATA PROCESSING COMPLETED SUCCESSFULLY in {duration.total_seconds():.2f} seconds"
                )
                print(f"Processed data for {datetime.now().date()}")
            else:
                print(
                    f"\nDATA PROCESSING FAILED after {duration.total_seconds():.2f} seconds"
                )
                print("Check logs for details")

        except Exception as e:
            print(f"\nCRITICAL ERROR IN DATA PROCESSING: {str(e)}")
            traceback.print_exc()
    else:
        print("\nNo raw data was saved today. Skipping data processing.")

    print("\nWeb search cron job completed!")


# if __name__ == "__main__":
#     get_raw_data()


def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è cron job"""
    print(f"\nüöÄ –ó–ê–ü–£–°–ö –ï–ñ–ï–î–ù–ï–í–ù–û–ô –û–ë–†–ê–ë–û–¢–ö–ò –î–ê–ù–ù–´–•: {datetime.now()}")

    success = process_todays_data()

    if success:
        print(f"\n–û–ë–†–ê–ë–û–¢–ö–ê –ó–ê–í–ï–†–®–ï–ù–ê –£–°–ü–ï–®–ù–û: {datetime.now()}")
    else:
        print(f"\n–û–ë–†–ê–ë–û–¢–ö–ê –ó–ê–í–ï–†–®–ï–ù–ê –° –û–®–ò–ë–ö–ê–ú–ò: {datetime.now()}")
        exit(1)


if __name__ == "__main__":
    main()
